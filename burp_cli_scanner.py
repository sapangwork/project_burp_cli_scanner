import os
import time
import json
import csv
import requests
import threading
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime
import html
import sys

# ================= è¨­å®šå€¼ =================
BURP_API_URL = "http://localhost:1337/v0.1"
API_KEY = ""  # è‹¥æœ‰è¨­å®šè«‹å¡«å…¥
MAX_RETRIES = 5
# =========================================

# å…¨åŸŸè®Šæ•¸
scan_states = {}
all_session_results = []
issue_definitions_map = {}
completed_tasks = 0
total_tasks = 0
lock = threading.Lock()
stop_dashboard_flag = False
CURRENT_SCAN_CONFIG = "Crawl and Audit - Fast"
API_ONLINE = False

# [NEW] æ—¥èªŒèˆ‡æ™‚é–“è¨˜éŒ„
scan_logs = []  # æ‰€æœ‰æ—¥èªŒè¨˜éŒ„
scan_time_records = {}  # å„ç«™é»æ™‚é–“è¨˜éŒ„ {url: {start, end, duration}}
session_start_time = None
session_end_time = None

class ANSI:
    CYAN, GREEN, YELLOW, RED, RESET, BOLD = '\033[96m', '\033[92m', '\033[93m', '\033[91m', '\033[0m', '\033[1m'
    GREY = '\033[90m'
    CLEAR = 'cls' if os.name == 'nt' else 'clear'

def clear_screen():
    os.system(ANSI.CLEAR)

# [NEW] æ—¥èªŒè¨˜éŒ„å‡½æ•¸
def log_event(level, message, url=None):
    """è¨˜éŒ„äº‹ä»¶åˆ°æ—¥èªŒç³»çµ±"""
    timestamp = datetime.now().isoformat()
    log_entry = {
        "timestamp": timestamp,
        "level": level,  # INFO, WARNING, ERROR, SUCCESS
        "message": message,
        "url": url
    }
    with lock:
        scan_logs.append(log_entry)
    
    # åŒæ™‚è¼¸å‡ºåˆ°æ§åˆ¶å°(å¯é¸)
    if level == "ERROR":
        print(f"{ANSI.RED}[{level}] {message}{ANSI.RESET}")

# --- 0. API æª¢æŸ¥èˆ‡ KB è¼‰å…¥ ---
def check_api_and_load_kb():
    global API_ONLINE, issue_definitions_map
    headers = {}
    if API_KEY: headers["X-Burp-API-Key"] = API_KEY
    
    try:
        requests.get(f"{BURP_API_URL.replace('/v0.1','')}/api-definition", headers=headers, timeout=2)
        API_ONLINE = True
        log_event("INFO", "Burp API é€£ç·šæˆåŠŸ")
        
        if not issue_definitions_map:
            print(f"\n{ANSI.CYAN}[*] åµæ¸¬åˆ° Burp ä¸Šç·š,æ­£åœ¨è¼‰å…¥çŸ¥è­˜åº«...{ANSI.RESET}")
            try:
                resp = requests.get(f"{BURP_API_URL}/knowledge_base/issue_definitions", headers=headers, timeout=10)
                if resp.status_code == 200:
                    defs = resp.json()
                    for d in defs:
                        try:
                            if d.get("issue_type_id"):
                                issue_definitions_map[int(d.get("issue_type_id"), 16)] = d
                        except: pass
                    print(f"{ANSI.GREEN}[+] çŸ¥è­˜åº«è¼‰å…¥å®Œæˆ (å…± {len(issue_definitions_map)} ç­†){ANSI.RESET}")
                    log_event("SUCCESS", f"çŸ¥è­˜åº«è¼‰å…¥å®Œæˆ: {len(issue_definitions_map)} ç­†å®šç¾©")
                    time.sleep(1.5)
                else:
                    log_event("ERROR", f"çŸ¥è­˜åº«è¼‰å…¥å¤±æ•—: HTTP {resp.status_code}")
            except Exception as e:
                log_event("ERROR", f"çŸ¥è­˜åº«è¼‰å…¥éŒ¯èª¤: {e}")
        return True
    except:
        API_ONLINE = False
        log_event("WARNING", "Burp API é›¢ç·š")
        return False

# --- 1. åˆä½µè³‡æ–™é‚è¼¯ ---
def merge_issue_data(issue):
    type_idx = issue.get("type_index")
    definition = issue_definitions_map.get(type_idx, {})
    if not issue.get("issue_background"): issue["issue_background"] = definition.get("description", "")
    if not issue.get("remediation_background"): issue["remediation_background"] = definition.get("remediation", "")
    if not issue.get("references") and definition.get("references"): issue["references"] = definition.get("references")
    if not issue.get("description"): issue["description"] = issue.get("issue_background", "")
    return issue

# --- 2. æƒæç­–ç•¥é¸æ“‡ ---
def select_scan_config():
    global CURRENT_SCAN_CONFIG
    configs = [
        "Crawl and Audit - Fast", "Crawl and Audit - Balanced", 
        "Crawl and Audit - Deep", "Crawl and Audit - Lightweight", "Audit checks - All issues"
    ]
    print(f"\n{ANSI.BOLD}è«‹é¸æ“‡æƒæç­–ç•¥ (Scan Configuration):{ANSI.RESET}")
    for idx, cfg in enumerate(configs): print(f"{idx + 1}. {cfg}")
    choice = input(f"è«‹è¼¸å…¥é¸é … (é è¨­ 1 - Fast): ").strip()
    try: idx = int(choice) - 1; CURRENT_SCAN_CONFIG = configs[idx] if 0 <= idx < len(configs) else configs[0]
    except: CURRENT_SCAN_CONFIG = configs[0]
    print(f"{ANSI.GREEN}å·²è¨­å®šç­–ç•¥ç‚º: {CURRENT_SCAN_CONFIG}{ANSI.RESET}\n")
    log_event("INFO", f"æƒæç­–ç•¥è¨­å®š: {CURRENT_SCAN_CONFIG}")
    time.sleep(1)

# --- 3. å ±å‘Šç”Ÿæˆå™¨ (å¢å¼·ç‰ˆ) ---
def generate_reports(url, issues, output_dir, scan_config, task_id="-", start_time=None, end_time=None):
    timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')
    safe_name = url.replace("http://", "").replace("https://", "").replace(":", "_").replace("/", "_")
    enriched_issues = [merge_issue_data(i) for i in issues]
    
    # è¨ˆç®—æƒææ™‚é•·
    duration_seconds = None
    if start_time and end_time:
        duration_seconds = (end_time - start_time).total_seconds()
    
    # JSON
    json_filename = os.path.join(output_dir, f"{timestamp_str}_Data_{safe_name}.json")
    try:
        json_data = {
            "target_url": url,
            "scan_configuration": scan_config,
            "task_id": task_id,
            "scan_start_time": start_time.isoformat() if start_time else None,
            "scan_end_time": end_time.isoformat() if end_time else None,
            "scan_duration_seconds": duration_seconds,
            "generated_at": datetime.now().isoformat(),
            "issue_count": len(enriched_issues),
            "issues": enriched_issues
        }
        with open(json_filename, "w", encoding="utf-8") as f:
            json.dump(json_data, f, ensure_ascii=False, indent=4)
    except Exception as e:
        log_event("ERROR", f"JSON ç”ŸæˆéŒ¯èª¤: {e}", url)

    # HTML (å¢å¼·ç‰ˆ - åŠ å…¥æ™‚é–“è³‡è¨Š)
    def normalize_severity(raw_sev):
        s = str(raw_sev).lower() if raw_sev else ""
        if "high" in s: return "High"
        if "medium" in s: return "Medium"
        if "low" in s: return "Low"
        return "Information"

    severity_counts = {"High": 0, "Medium": 0, "Low": 0, "Information": 0}
    severity_order = {"High": 0, "Medium": 1, "Low": 2, "Information": 3}
    processed_issues = []
    for issue in enriched_issues:
        norm_sev = normalize_severity(issue.get('severity', 'Information'))
        issue['_normalized_severity'] = norm_sev
        if norm_sev in severity_counts: severity_counts[norm_sev] += 1
        processed_issues.append(issue)
    processed_issues.sort(key=lambda x: severity_order.get(x['_normalized_severity'], 4))

    html_filename = os.path.join(output_dir, f"{timestamp_str}_Report_{safe_name}.html")
    css = """
    body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif; background: #f9f9f9; color: #333; margin: 0; padding: 20px; }
    .container { max-width: 1000px; margin: 0 auto; background: #fff; padding: 30px; border-radius: 5px; box-shadow: 0 2px 5px rgba(0,0,0,0.1); }
    h1 { border-bottom: 2px solid #e04006; padding-bottom: 10px; color: #e04006; }
    .meta { background: #eee; padding: 10px; margin-bottom: 20px; border-radius: 4px; }
    .time-info { background: #d4edda; padding: 10px; margin-bottom: 20px; border-radius: 4px; border-left: 4px solid #28a745; }
    .summary-box { display: flex; gap: 10px; margin-bottom: 30px; }
    .stat-card { flex: 1; padding: 15px; text-align: center; color: #fff; border-radius: 4px; font-weight: bold; }
    .High { background: #ff3333; } .Medium { background: #ff9933; } .Low { background: #3399ff; } .Information { background: #808080; }
    details { margin-bottom: 10px; border: 1px solid #ddd; border-radius: 4px; overflow: hidden; }
    summary { padding: 12px; cursor: pointer; background: #f1f1f1; font-weight: bold; display: flex; justify-content: space-between; align-items: center; }
    .issue-content { padding: 20px; background: #fff; border-top: 1px solid #ddd; }
    .tag { padding: 3px 8px; border-radius: 10px; font-size: 0.8em; color: white; margin-right: 10px; }
    .path { font-family: monospace; color: #555; background: #eee; padding: 2px 5px; border-radius: 3px; word-break: break-all; }
    .section-title { font-size: 1.1em; font-weight: bold; margin-top: 20px; margin-bottom: 10px; color: #e04006; border-left: 4px solid #e04006; padding-left: 8px; }
    .bg-section { color: #555; font-size: 0.95em; }
    """
    
    # æ™‚é–“è³‡è¨Šå€å¡Š
    time_info_html = ""
    if start_time and end_time:
        time_info_html = f"""
        <div class="time-info">
            <strong>ğŸ•’ æƒææ™‚é–“è³‡è¨Š:</strong><br>
            é–‹å§‹æ™‚é–“: {start_time.strftime('%Y-%m-%d %H:%M:%S')}<br>
            çµæŸæ™‚é–“: {end_time.strftime('%Y-%m-%d %H:%M:%S')}<br>
            æƒææ™‚é•·: {int(duration_seconds // 60)} åˆ† {int(duration_seconds % 60)} ç§’
        </div>
        """
    
    html_content = f"""<!DOCTYPE html><html><head><meta charset="UTF-8"><title>Report: {url}</title><style>{css}</style></head><body>
    <div class="container"><h1>Burp Scan Report</h1>
    <div class="meta"><strong>Target:</strong> {url}<br><strong>Config:</strong> {scan_config}<br><strong>ID:</strong> {task_id}<br><strong>Generated:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</div>
    {time_info_html}
    <div class="summary-box"><div class="stat-card High">High: {severity_counts['High']}</div><div class="stat-card Medium">Medium: {severity_counts['Medium']}</div><div class="stat-card Low">Low: {severity_counts['Low']}</div><div class="stat-card Information">Info: {severity_counts['Information']}</div></div>
    <h2>Issue Details</h2>"""

    if not processed_issues: html_content += "<p>No issues found.</p>"
    else:
        for issue in processed_issues:
            name, sev, path = html.escape(issue.get('name', 'Unknown')), issue['_normalized_severity'], html.escape(issue.get('path', '/'))
            content_html = ""
            if issue.get('description'): content_html += f'<div class="section-title">Detail</div><div>{issue["description"]}</div>'
            if issue.get('issue_background'): content_html += f'<div class="section-title">Background</div><div class="bg-section">{issue["issue_background"]}</div>'
            if issue.get('evidence'): content_html += f'<div class="section-title">Evidence</div><div><ul>' + "".join([f"<li>{html.escape(str(e))}</li>" for e in issue['evidence']]) + '</ul></div>'
            if issue.get('remediation'): content_html += f'<div class="section-title">Remediation</div><div>{issue["remediation"]}</div>'
            if issue.get('remediation_background'): content_html += f'<div class="section-title">Gen. Remediation</div><div class="bg-section">{issue["remediation_background"]}</div>'
            if issue.get('references'): content_html += f'<div class="section-title">References</div><div>{issue["references"]}</div>'
            
            html_content += f"""<details><summary><span><span class="tag {sev}">{sev}</span> {name}</span></summary><div class="issue-content"><p><strong>Path:</strong> <span class="path">{path}</span></p>{content_html}</div></details>"""
    
    html_content += "</div></body></html>"
    with open(html_filename, "w", encoding="utf-8") as f: f.write(html_content)
    
    return {"url": url, "issues": len(enriched_issues), "severity_counts": severity_counts}, html_filename

# --- 4. åŒ¯å‡º UI ---
def export_existing_tasks_ui(report_dir):
    clear_screen()
    print(f"{ANSI.BOLD}=== åŒ¯å‡º Burp ç¾æœ‰ä»»å‹™å ±å‘Š ==={ANSI.RESET}")
    headers = {} if not API_KEY else {"X-Burp-API-Key": API_KEY}
    id_input = input(f"{ANSI.YELLOW}è«‹è¼¸å…¥ Task ID (é€—è™Ÿåˆ†éš”): {ANSI.RESET}").strip()
    if not id_input: return
    print("-" * 75)
    print(f"{'ID':<5} | {'Status':<15} | {'Result':<50}")
    print("-" * 75)
    for t_id in [x.strip() for x in id_input.split(',')]:
        try:
            r = requests.get(f"{BURP_API_URL}/scan/{t_id}", headers=headers, timeout=5)
            if r.status_code == 200:
                data = r.json()
                events = data.get("issue_events", [])
                issues = [e.get("issue") for e in events if e.get("type") == "issue_found" and e.get("issue")]
                origin = issues[0].get("origin", "Unknown") if issues else "Unknown"
                if issues:
                    _, html_path = generate_reports(origin, issues, report_dir, "Existing", t_id)
                    print(f"{t_id:<5} | {ANSI.GREEN}{data.get('scan_status','?')[:15]:<15}{ANSI.RESET} | {os.path.basename(html_path)}")
                    log_event("SUCCESS", f"åŒ¯å‡ºä»»å‹™ {t_id} æˆåŠŸ", origin)
                else: print(f"{t_id:<5} | {data.get('scan_status','?'):<15} | {ANSI.YELLOW}ç„¡æ¼æ´/æœªå®Œæˆ{ANSI.RESET}")
            else: print(f"{t_id:<5} | {ANSI.RED}Not Found{ANSI.RESET}     | HTTP {r.status_code}")
        except Exception as e:
            print(f"{t_id:<5} | {ANSI.RED}Error{ANSI.RESET}         | {e}")
            log_event("ERROR", f"åŒ¯å‡ºä»»å‹™ {t_id} å¤±æ•—: {e}")
    print("-" * 75); input("\næŒ‰ Enter å›é¸å–®...")

# --- 5. æƒææ ¸å¿ƒ (å¢å¼·ç‰ˆ - è¨˜éŒ„æ™‚é–“) ---
def run_scan_task(url, report_dir):
    global completed_tasks, scan_time_records
    url = url.strip()
    
    # è¨˜éŒ„é–‹å§‹æ™‚é–“
    start_time = datetime.now()
    with lock:
        scan_states[url].update({"status": "Starting", "task_id": "Init"})
        scan_time_records[url] = {"start": start_time, "end": None, "duration": None}
    
    log_event("INFO", f"é–‹å§‹æƒæ", url)
    
    headers = {} if not API_KEY else {"X-Burp-API-Key": API_KEY}
    
    try:
        payload = {"urls": [url], "scan_configurations": [{"name": CURRENT_SCAN_CONFIG, "type": "NamedConfiguration"}]}
        resp = requests.post(f"{BURP_API_URL}/scan", json=payload, headers=headers, timeout=5)
        if resp.status_code == 201:
            task_id = resp.headers.get("Location").split("/")[-1]
            with lock: scan_states[url].update({"task_id": task_id, "status": "Wait 3s..."})
            log_event("SUCCESS", f"ä»»å‹™ {task_id} å»ºç«‹æˆåŠŸ", url)
            time.sleep(3)
        else:
            with lock: scan_states[url]["status"] = f"Err {resp.status_code}"; completed_tasks += 1
            log_event("ERROR", f"ä»»å‹™å»ºç«‹å¤±æ•—: HTTP {resp.status_code}", url)
            return
    except Exception as e:
        with lock: scan_states[url]["status"] = "Conn Fail"; completed_tasks += 1
        log_event("ERROR", f"é€£ç·šå¤±æ•—: {e}", url)
        return

    task_id = scan_states[url]["task_id"]
    final_data = {}
    
    while True:
        try:
            r = requests.get(f"{BURP_API_URL}/scan/{task_id}", headers=headers, timeout=5)
            if r.status_code == 200:
                data = r.json()
                final_data = data
                status = data.get("scan_status")
                metrics = data.get("scan_metrics", {})
                reqs = metrics.get("crawl_requests_made", metrics.get("audit_queue_items_completed", 0))
                issue_count = len([e for e in data.get("issue_events", []) if e.get("type") == "issue_found"])
                with lock: scan_states[url].update({"status": status, "reqs": reqs, "issues": issue_count})
                if status in ["succeeded", "failed"]: break
            time.sleep(2)
        except Exception as e:
            with lock: scan_states[url]["status"] = "Burp Lost"
            log_event("ERROR", f"æƒæéç¨‹ä¸­æ–·: {e}", url)
            break

    # è¨˜éŒ„çµæŸæ™‚é–“
    end_time = datetime.now()
    duration = (end_time - start_time).total_seconds()
    with lock:
        scan_time_records[url]["end"] = end_time
        scan_time_records[url]["duration"] = duration

    if scan_states[url]["status"] != "Burp Lost" and final_data:
        with lock: scan_states[url]["status"] = "Reporting"
        issues = [e.get("issue") for e in final_data.get("issue_events", []) if e.get("type") == "issue_found"]
        report_data, _ = generate_reports(url, issues, report_dir, CURRENT_SCAN_CONFIG, task_id, start_time, end_time)
        with lock:
            all_session_results.append(report_data)
            scan_states[url]["status"] = "Completed"
        log_event("SUCCESS", f"æƒæå®Œæˆ - ç™¼ç¾ {len(issues)} å€‹å•é¡Œ,è€—æ™‚ {int(duration)}ç§’", url)
    else:
        if scan_states[url]["status"] != "Burp Lost":
            with lock: scan_states[url]["status"] = "Failed"
        log_event("ERROR", "æƒæå¤±æ•—", url)
    
    with lock: completed_tasks += 1

# --- 6. Dashboard ---
def dashboard_loop():
    while not stop_dashboard_flag:
        clear_screen()
        print(f"{ANSI.BOLD}Burp Suite Pro è‡ªå‹•åŒ–æƒæ v11.0 (Enhanced Logging){ANSI.RESET}")
        print(f"é€²åº¦: {completed_tasks}/{total_tasks} | ç­–ç•¥: {CURRENT_SCAN_CONFIG}")
        print("-" * 90)
        print(f"{'URL':<35} | {'ID':<5} | {'Status':<15} | {'Reqs':<6} | {'Issues':<6}")
        print("-" * 90)
        with lock:
            for url, s in scan_states.items():
                st, c = s['status'], ANSI.YELLOW
                if "scann" in st.lower() or "crawl" in st.lower(): c = ANSI.GREEN
                elif st == "Waiting": c = ANSI.GREY
                elif st == "Completed": c = ANSI.CYAN
                elif "fail" in st.lower() or "lost" in st.lower() or "err" in st.lower(): c = ANSI.RED
                print(f"{(url[:32] + '..') if len(url) > 32 else url:<35} | {s.get('task_id','-'):<5} | {c}{st:<15}{ANSI.RESET} | {s['reqs']:<6} | {ANSI.RED}{s['issues']:<6}{ANSI.RESET}")
        print("-" * 90)
        time.sleep(1)

# --- 7. [NEW] åŒ¯å‡ºæ—¥èªŒèˆ‡çµ±è¨ˆå ±å‘Š ---
def export_logs_and_statistics(report_dir):
    """åŒ¯å‡ºå®Œæ•´æ—¥èªŒå’Œçµ±è¨ˆè³‡æ–™"""
    timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # 1. åŒ¯å‡º JSON æ—¥èªŒ
    log_json_path = os.path.join(report_dir, f"{timestamp_str}_Scan_Logs.json")
    try:
        with open(log_json_path, "w", encoding="utf-8") as f:
            json.dump({
                "session_start": session_start_time.isoformat() if session_start_time else None,
                "session_end": session_end_time.isoformat() if session_end_time else None,
                "total_events": len(scan_logs),
                "logs": scan_logs
            }, f, ensure_ascii=False, indent=4)
        print(f"{ANSI.GREEN}[+] æ—¥èªŒå·²åŒ¯å‡º: {log_json_path}{ANSI.RESET}")
    except Exception as e:
        print(f"{ANSI.RED}[!] æ—¥èªŒåŒ¯å‡ºå¤±æ•—: {e}{ANSI.RESET}")
    
    # 2. åŒ¯å‡º CSV çµ±è¨ˆå ±å‘Š
    csv_path = os.path.join(report_dir, f"{timestamp_str}_Scan_Statistics.csv")
    try:
        with open(csv_path, "w", newline='', encoding="utf-8-sig") as csvfile:
            fieldnames = ['URL', 'Task_ID', 'Status', 'Start_Time', 'End_Time', 'Duration_Sec', 
                         'High', 'Medium', 'Low', 'Information', 'Total_Issues']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            
            with lock:
                for url, state in scan_states.items():
                    time_record = scan_time_records.get(url, {})
                    
                    # å¾ all_session_results æ‰¾åˆ°å°æ‡‰çš„çµ±è¨ˆ
                    severity_data = {"High": 0, "Medium": 0, "Low": 0, "Information": 0}
                    total_issues = 0
                    for result in all_session_results:
                        if result.get("url") == url:
                            severity_data = result.get("severity_counts", severity_data)
                            total_issues = result.get("issues", 0)
                            break
                    
                    writer.writerow({
                        'URL': url,
                        'Task_ID': state.get('task_id', '-'),
                        'Status': state.get('status', 'Unknown'),
                        'Start_Time': time_record.get('start').strftime('%Y-%m-%d %H:%M:%S') if time_record.get('start') else '',
                        'End_Time': time_record.get('end').strftime('%Y-%m-%d %H:%M:%S') if time_record.get('end') else '',
                        'Duration_Sec': int(time_record.get('duration', 0)) if time_record.get('duration') else 0,
                        'High': severity_data.get('High', 0),
                        'Medium': severity_data.get('Medium', 0),
                        'Low': severity_data.get('Low', 0),
                        'Information': severity_data.get('Information', 0),
                        'Total_Issues': total_issues
                    })
        print(f"{ANSI.GREEN}[+] çµ±è¨ˆå ±å‘Šå·²åŒ¯å‡º: {csv_path}{ANSI.RESET}")
    except Exception as e:
        print(f"{ANSI.RED}[!] CSV åŒ¯å‡ºå¤±æ•—: {e}{ANSI.RESET}")
    
    # 3. åŒ¯å‡ºç¸½è¦½ JSON
    summary_path = os.path.join(report_dir, f"{timestamp_str}_Session_Summary.json")
    try:
        total_duration = (session_end_time - session_start_time).total_seconds() if session_start_time and session_end_time else 0
        
        summary_data = {
            "session_info": {
                "start_time": session_start_time.isoformat() if session_start_time else None,
                "end_time": session_end_time.isoformat() if session_end_time else None,
                "total_duration_seconds": total_duration,
                "scan_configuration": CURRENT_SCAN_CONFIG,
                "total_targets": total_tasks,
                "completed_targets": completed_tasks
            },
            "aggregate_statistics": {
                "total_high": sum(r.get("severity_counts", {}).get("High", 0) for r in all_session_results),
                "total_medium": sum(r.get("severity_counts", {}).get("Medium", 0) for r in all_session_results),
                "total_low": sum(r.get("severity_counts", {}).get("Low", 0) for r in all_session_results),
                "total_information": sum(r.get("severity_counts", {}).get("Information", 0) for r in all_session_results),
                "total_issues": sum(r.get("issues", 0) for r in all_session_results)
            },
            "scan_details": []
        }
        
        for url, state in scan_states.items():
            time_record = scan_time_records.get(url, {})
            severity_data = {"High": 0, "Medium": 0, "Low": 0, "Information": 0}
            total_issues = 0
            
            for result in all_session_results:
                if result.get("url") == url:
                    severity_data = result.get("severity_counts", severity_data)
                    total_issues = result.get("issues", 0)
                    break
            
            summary_data["scan_details"].append({
                "url": url,
                "task_id": state.get('task_id', '-'),
                "status": state.get('status', 'Unknown'),
                "start_time": time_record.get('start').isoformat() if time_record.get('start') else None,
                "end_time": time_record.get('end').isoformat() if time_record.get('end') else None,
                "duration_seconds": time_record.get('duration', 0),
                "severity_counts": severity_data,
                "total_issues": total_issues
            })
        
        with open(summary_path, "w", encoding="utf-8") as f:
            json.dump(summary_data, f, ensure_ascii=False, indent=4)
        print(f"{ANSI.GREEN}[+] æœƒè©±ç¸½è¦½å·²åŒ¯å‡º: {summary_path}{ANSI.RESET}")
    except Exception as e:
        print(f"{ANSI.RED}[!] ç¸½è¦½åŒ¯å‡ºå¤±æ•—: {e}{ANSI.RESET}")

# --- 8. ä¸»ç¨‹å¼ ---
def main():
    global total_tasks, completed_tasks, scan_states, stop_dashboard_flag, all_session_results
    global session_start_time, session_end_time, scan_logs, scan_time_records
    
    while True:
        check_api_and_load_kb()
        
        clear_screen()
        print(f"{ANSI.BOLD}=== Burp Suite è‡ªå‹•åŒ–æª¢æ¸¬å·¥å…· v11.0 (Enhanced) ==={ANSI.RESET}")
        
        if API_ONLINE:
            print(f"API ç‹€æ…‹: {ANSI.GREEN}Online{ANSI.RESET}")
            kb_status = f"{ANSI.GREEN}å·²è¼‰å…¥ ({len(issue_definitions_map)}){ANSI.RESET}" if issue_definitions_map else f"{ANSI.YELLOW}è¼‰å…¥ä¸­...{ANSI.RESET}"
            print(f"çŸ¥è­˜åº«: {kb_status}")
            print("-" * 40)
            print("1. åŸ·è¡Œæ‰¹é‡æƒæ (New Scan)")
            print("2. åŒ¯å‡ºæ—¢æœ‰ä»»å‹™ (Export Existing)")
            print("q. é›¢é–‹ç¨‹å¼ (Quit)")
            print("-" * 40)
            prompt = "è«‹è¼¸å…¥é¸é …: "
        else:
            print(f"API ç‹€æ…‹: {ANSI.RED}Offline (ç­‰å¾… Burp é€£ç·šä¸­...){ANSI.RESET}")
            print(f"çŸ¥è­˜åº«: {ANSI.GREY}ç­‰å¾…é€£ç·š{ANSI.RESET}")
            print("-" * 40)
            print(f"{ANSI.YELLOW}[!] Burp æœªå•Ÿå‹•ã€‚ç¨‹å¼å°‡æ¯ 5 ç§’è‡ªå‹•é‡è©¦é€£ç·š...{ANSI.RESET}")
            print("q. é›¢é–‹ç¨‹å¼ (Quit)")
            print("-" * 40)
            prompt = "è«‹è¼¸å…¥é¸é … (æˆ–æŒ‰ Enter é‡æ–°æª¢æŸ¥): "

        try:
            if not API_ONLINE:
                print(f"{ANSI.CYAN}æ­£åœ¨å˜—è©¦é€£ç·šè‡³ {BURP_API_URL}... (æŒ‰ Ctrl+C å¼·åˆ¶é›¢é–‹){ANSI.RESET}")
                time.sleep(3)
                continue
                
            choice = input(prompt).strip().lower()
        except KeyboardInterrupt:
            print("\nBye!"); break

        if choice in ['q', 'quit']:
            print("Bye!"); break

        if not API_ONLINE:
            continue

        report_dir = "reports"
        if not os.path.exists(report_dir): os.makedirs(report_dir)

        if choice == '2':
            export_existing_tasks_ui(report_dir)
        elif choice == '1':
            # é‡ç½®æ‰€æœ‰ç‹€æ…‹
            with lock:
                scan_states = {}
                all_session_results = []
                completed_tasks = 0
                total_tasks = 0
                stop_dashboard_flag = False
                scan_logs = []
                scan_time_records = {}
                session_start_time = None
                session_end_time = None
            
            url_file = input("ç¶²å€æ¸…å–® (é è¨­ urls.txt): ").strip() or "urls.txt"
            if not os.path.exists(url_file):
                print(f"{ANSI.RED}æ‰¾ä¸åˆ°æª”æ¡ˆ!{ANSI.RESET}")
                time.sleep(1)
                continue
            
            select_scan_config()
            try: workers = int(input("ä¸¦è¡Œæ•¸ (é è¨­ 2): ").strip() or "2")
            except: workers = 2
            
            with open(url_file, "r") as f:
                raw_urls = [line.strip() for line in f if line.strip()]
                urls = list(dict.fromkeys(raw_urls))
            
            total_tasks = len(urls)
            if total_tasks == 0:
                print("æ¸…å–®æ˜¯ç©ºçš„ã€‚")
                time.sleep(1)
                continue
            
            # è¨˜éŒ„æœƒè©±é–‹å§‹æ™‚é–“
            session_start_time = datetime.now()
            log_event("INFO", f"æƒææœƒè©±é–‹å§‹ - å…± {total_tasks} å€‹ç›®æ¨™")
            
            with lock:
                for u in urls: scan_states[u] = {"status": "Waiting", "reqs": 0, "issues": 0, "task_id": "-"}
            
            ui_thread = threading.Thread(target=dashboard_loop, daemon=True)
            ui_thread.start()
            
            with ThreadPoolExecutor(max_workers=workers) as executor:
                for url in urls:
                    time.sleep(0.5)
                    executor.submit(run_scan_task, url, report_dir)
            
            while completed_tasks < total_tasks: time.sleep(1)
            stop_dashboard_flag = True
            ui_thread.join()
            
            # è¨˜éŒ„æœƒè©±çµæŸæ™‚é–“
            session_end_time = datetime.now()
            log_event("INFO", f"æƒææœƒè©±çµæŸ - å®Œæˆ {completed_tasks}/{total_tasks} å€‹ç›®æ¨™")
            
            # æœ€å¾Œé¡¯ç¤ºå®Œæ•´ Dashboard
            clear_screen()
            print(f"{ANSI.BOLD}Burp Suite Pro è‡ªå‹•åŒ–æƒæ v11.0 (Completed){ANSI.RESET}")
            print(f"é€²åº¦: {completed_tasks}/{total_tasks} | ç­–ç•¥: {CURRENT_SCAN_CONFIG}")
            
            if session_start_time and session_end_time:
                total_duration = (session_end_time - session_start_time).total_seconds()
                print(f"æœƒè©±æ™‚é–“: {session_start_time.strftime('%H:%M:%S')} - {session_end_time.strftime('%H:%M:%S')} (å…± {int(total_duration//60)}åˆ†{int(total_duration%60)}ç§’)")
            
            print("-" * 90)
            print(f"{'URL':<35} | {'ID':<5} | {'Status':<15} | {'Reqs':<6} | {'Issues':<6}")
            print("-" * 90)
            with lock:
                for url, s in scan_states.items():
                    color = ANSI.CYAN if s['status'] == "Completed" else ANSI.RED
                    print(f"{(url[:32] + '..') if len(url) > 32 else url:<35} | {s.get('task_id','-'):<5} | {color}{s['status']:<15}{ANSI.RESET} | {s['reqs']:<6} | {ANSI.RED}{s['issues']:<6}{ANSI.RESET}")
            print("-" * 90)

            # åŒ¯å‡ºæ—¥èªŒèˆ‡çµ±è¨ˆ
            print(f"\n{ANSI.CYAN}æ­£åœ¨åŒ¯å‡ºæ—¥èªŒèˆ‡çµ±è¨ˆå ±å‘Š...{ANSI.RESET}")
            export_logs_and_statistics(report_dir)
            
            input(f"\n{ANSI.CYAN}æŒ‰ Enter å›ä¸»é¸å–®...{ANSI.RESET}")
        else:
            print("ç„¡æ•ˆé¸é …ã€‚")
            time.sleep(0.5)

if __name__ == "__main__":
    main()